{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature Set Using a Variety of NLP techniques\n",
    "\n",
    "1. Attempted Random Forest & gradient boost classification models on entire congress dataset to predict the speakers political party.\n",
    "    1. Results - accuracy was not great. The range of topics and individual speakers may be too dificult a challenge\n",
    "    2. Note - Pipelines for this section are actually on the bottom. Since classification worked better with just 1 debate topic I kept those pipelines near the top\n",
    "\n",
    "2. Classification models on top debate (debate num.132 which has >350 rep and 350 dem speech segments)\n",
    "    1. Results - accuracy greatly improved from general models\n",
    "    2. Successfully extracted a features set using word2vec Note: could not figure out normalize function \n",
    "    3. Didn't see a huge difference in accuracy between NLP feature sets\n",
    "    4. Question: is there an efficient way to check how accurate a word2vec model is besides checking how it scores the similarity between words I consider similar?\n",
    "    \n",
    "3. Attempting Clustering on 14 speakers with the most speech segments - haven't done this yet so here are the steps I'm trying to complete before Tuesday session:\n",
    "    1. Set up a pipeline that will Build a TFIDF feature set on 80% of sample speeches\n",
    "    2. Try out a method of clustering on sample speeches - see if there are any obvious patterns\n",
    "    3. Next step would be based on if obvious pattern pops up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from gensim import utils, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the file names in the development set\n",
    "def pywalker(path):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file_ in files:\n",
    "            file_list.append( os.path.join(root, file_) )\n",
    "    return file_list\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    pywalker('/path/to/some/folder')\n",
    "\n",
    "def import_files(file_list, path):\n",
    "    debate_list = []\n",
    "    speaker_list = []\n",
    "    page_list = []\n",
    "    page_position_list = []\n",
    "    party_list = []\n",
    "    mention_list = []\n",
    "    vote_list = []\n",
    "    file_text = []\n",
    "\n",
    "    for file in file_list:\n",
    "        # Read the speech segment and add to \n",
    "        myfile = open(file)\n",
    "        file_text.append(myfile.read())\n",
    "        myfile.close()\n",
    "        \n",
    "        file = file.replace((str(path)+'/'),'').replace('.txt','')\n",
    "        debate_list.append(file[0:3])\n",
    "        speaker_list.append(file[4:10])\n",
    "        page_list.append(file[11:15])\n",
    "        page_position_list.append(file[15:18])\n",
    "        party_list.append(file[-3])\n",
    "        mention_list.append(file[-2])\n",
    "        vote_list.append(file[-1])\n",
    "\n",
    "\n",
    "    columns = ['file_name', 'debate', 'speaker', 'page', 'page_position', \n",
    "               'party', 'mention', 'vote', 'speech']\n",
    "\n",
    "    data = {'file_name':file_list, 'debate':debate_list, \n",
    "            'speaker':speaker_list, 'page':page_list, \n",
    "            'page_position':page_position_list,\n",
    "            'party':party_list, 'mention':mention_list, \n",
    "            'vote':vote_list, 'speech':file_text}\n",
    "\n",
    "    text_details = pd.DataFrame(data=data, columns = columns)\n",
    "    \n",
    "    return text_details\n",
    "\n",
    "\n",
    "def random_sort(table):\n",
    "    table['random'] = np.random.rand(len(table.index),1)\n",
    "    table = table.sort_values(by='random')\n",
    "    table = table.reset_index(drop=True).drop(columns='random', axis=1)\n",
    "    return table\n",
    "\n",
    "# This function just clears out know features that are not needed\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'xz[0-9]{7}','', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a few things I want try\n",
    "1. See if I am able to create a better classifier if I work with just 1 debate\n",
    "    * bow\n",
    "    * tfidf\n",
    "    * word2vec\n",
    "2. Cluster on speaker (5 dems & 5 republicans with the most speech segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    0.523538\n",
       "D    0.476462\n",
       "Name: party, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set baseline for the accuracy score\n",
    "dev_text['party'].value_counts()/len(dev_text['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path = 'senate/data_stage_one/development_set'\n",
    "train_path = 'senate/data_stage_one/training_set'\n",
    "test_path = 'senate/data_stage_one/test_set'\n",
    "dev_text = import_files(pywalker(dev_path), dev_path)\n",
    "train_text = import_files(pywalker(train_path), train_path)\n",
    "test_text = import_files(pywalker(test_path), test_path)\n",
    "\n",
    "# I want to be able to easily see what original data source they are in (I have a feeling won't be that imp)\n",
    "dev_text['source'] = 'dev'\n",
    "train_text['source'] = 'train'\n",
    "test_text['source'] = 'test'\n",
    "\n",
    "# Put all speech segments in one doc\n",
    "full_text = pd.concat([dev_text, train_text, test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 1 dataset of the debate with most speeches & 1 dataset with the top 14 speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_text['speech_clean'] = dev_text['speech'].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are the top 5 dem and top 5 rep speakers\n",
    "top_14 = full_text.groupby(by=['speaker','party']).count().sort_values(by='source', ascending=False).iloc[:15,:]\n",
    "top_speaker = top_14.reset_index()['speaker']\n",
    "\n",
    "# Builds a dataset of just the speeches give by my top 14 speakers\n",
    "top_speaker = full_text[full_text['speaker'].isin(top_speaker)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debate  source  party\n",
       "132     train   R        383\n",
       "                D        369\n",
       "031     train   R        346\n",
       "088     train   D        340\n",
       "031     train   D        332\n",
       "Name: file_name, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_count = full_text.groupby(by=['debate', 'source', 'party']).count()['file_name']\n",
    "speech_count.sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to the top debate\n",
    "top_debate = full_text[full_text['debate']=='132'].reset_index(drop=True)\n",
    "\n",
    "# Clean top_debate for BOW & tfidf\n",
    "top_debate['speech_clean'] = top_debate['speech'].apply(lambda x: text_cleaner(x))\n",
    "top_debate = random_sort(top_debate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____ \n",
    "### TOP DEBATE\n",
    "Lets create a pipeline to test out classification on top_debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.641\n",
      "Cross Val: \n",
      "[0.60159363 0.61752988 0.628     ]\n",
      "\n",
      "Best parameters: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy',\n",
       " 'clf__max_depth': 7,\n",
       " 'clf__n_estimators': 70,\n",
       " 'svd__n_components': 70,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 2000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words using tfidf vectorizer\n",
    "X = top_debate['speech_clean']\n",
    "y = top_debate['party']\n",
    "\n",
    "\n",
    "# Training the BOW vectorizor\n",
    "bow_vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,      # if an integer vectorizer returns with most used words  \n",
    "    use_idf=False,          # Use IDF\n",
    "    norm=u'l2',             # Correction factor to treat long and short paragraphs equally\n",
    "    smooth_idf=True,        # Prevents divide-by-zero errors by adding one to all features\n",
    "    stop_words='english',  \n",
    "    lowercase=True,          \n",
    "                                 )\n",
    "pipeline = Pipeline([\n",
    "    ('vect', bow_vectorizer),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'svd__n_components': (50,70,),       #50\n",
    "    'clf__criterion': ('entropy',),\n",
    "    'clf__max_depth': (4,7,9, None),           #9\n",
    "    'clf__n_estimators': (70, 150,), #70\n",
    "    'vect__max_df': (0.5,),             # Drop words that appear in > x % of the paragraphs\n",
    "    'vect__max_features': (2000,),     # return top X used words\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Best score: %.3f'%grid_search.best_score_)\n",
    "print('Cross Val: \\n{}\\n'.format(cross_val_score(grid_search.best_estimator_, X, y, cv=3)))\n",
    "\n",
    "print('Best parameters:')\n",
    "grid_search.best_params_    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if gradient boost does a little more for me without adding overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.641\n",
      "Cross Val: \n",
      "[0.62151394 0.6374502  0.62      ]\n",
      "\n",
      "Best parameters: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.2,\n",
       " 'clf__max_depth': 7,\n",
       " 'clf__n_estimators': 70,\n",
       " 'clf__subsample': 0.5,\n",
       " 'svd__n_components': 50,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 2000}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words using tfidf vectorizer\n",
    "X = top_debate['speech_clean']\n",
    "y = top_debate['party']\n",
    "\n",
    "# Training the BOW vectorizor\n",
    "bow_vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,      # if an integer vectorizer returns with most used words  \n",
    "    use_idf=False,          # Use IDF\n",
    "    norm=u'l2',             # Correction factor to treat long and short paragraphs equally\n",
    "    smooth_idf=True,        # Prevents divide-by-zero errors by adding one to all features\n",
    "    stop_words='english',  \n",
    "    lowercase=True,          \n",
    "                                 )\n",
    "pipeline = Pipeline([\n",
    "    ('vect', bow_vectorizer),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__learning_rate': (0.2, 0.5, 0.8,),\n",
    "    'clf__max_depth': (4,7,None,),           #9\n",
    "    'clf__n_estimators': (50, 70, 100,), #70\n",
    "    'clf__subsample': (0.3, 0.5, 0.7),\n",
    "    'vect__max_df': (0.5,),             # Drop words that appear in > x % of the paragraphs\n",
    "    'vect__max_features': (2000,2500),     # return top X used words\n",
    "    'svd__n_components': (50,70,),       #50\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print('Best score: %.3f'%grid_search.best_score_)\n",
    "print('Cross Val: \\n{}\\n'.format(cross_val_score(grid_search.best_estimator_, X, y, cv=3)))\n",
    "print('Best parameters: \\n')\n",
    "grid_search.best_params_    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Random forest and grandient boost they seem to have very similar effectiveness with accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____ \n",
    "### TOP DEBATES\n",
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.660\n",
      "Cross Val: \n",
      "[0.63346614 0.62948207 0.696     ]\n",
      "\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy',\n",
       " 'clf__max_depth': 4,\n",
       " 'clf__n_estimators': 70,\n",
       " 'svd__n_components': 50,\n",
       " 'tfidf__max_df': 0.8,\n",
       " 'tfidf__min_df': 9}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF Optimizing th TFIDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,            # drop words that occur in more than half the paragraphs\n",
    "    min_df=2,              # Use words that appear >= 2x     \n",
    "    use_idf=True,          # Use IDF\n",
    "    norm=u'l2',            # Correction factor to treat long and short paragraphs equally\n",
    "    smooth_idf=True,        # Prevents divide-by-zero errors by adding one to all features\n",
    "    stop_words='english',  \n",
    "    lowercase=True,        \n",
    "    )\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__criterion': ('entropy',),\n",
    "    'clf__max_depth': (4,7,),\n",
    "    'clf__n_estimators': (70,130,),   \n",
    "    'svd__n_components': (50,70,),    \n",
    "    'tfidf__max_df': (0.5,0.8),\n",
    "    'tfidf__min_df': (2,5,9,),   \n",
    "}\n",
    "\n",
    "grid_search_tfidf = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search_tfidf.fit(X,y)\n",
    "\n",
    "print('Best score: %.3f'%grid_search_tfidf.best_score_)\n",
    "print('Cross Val: \\n{}\\n'.format(cross_val_score(grid_search_tfidf.best_estimator_, X, y, cv=3)))\n",
    "print('Best parameters:')\n",
    "grid_search_tfidf.best_params_    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### TOP DEBATES\n",
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X = top_debate['speech_clean']\n",
    "y = top_debate['party']\n",
    "top_debate['speech_processed'] = top_debate['speech_clean'].apply(lambda x: utils.simple_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document which is a list of all the speeches\n",
    "processed_text = list(top_debate['speech_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary and train model\n",
    "model = models.Word2Vec(\n",
    "        processed_text,\n",
    "        workers=4,     # Number of threads to run in parallel\n",
    "        min_count=10,  # Minimum word count threshold.\n",
    "        window=12,      # Number of words around target word to consider.\n",
    "        sg=0,          # Use CBOW because our corpus is small.\n",
    "        sample=1e-3 ,  # Penalize frequent words.\n",
    "        size=300,      # Word vector length.\n",
    "        hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "model.train(processed_text, total_examples=len(processed_text), epochs=10)\n",
    "\n",
    "def text_vector(doc):    \n",
    "    output_vec = np.zeros(model.vector_size)\n",
    "    for word in doc:\n",
    "        if word in model.wv.vocab:\n",
    "            output_vec += model[word]\n",
    "##### tried to use normalize but its doesn't like the input output_vec += normalize(model[word], axis=0)\n",
    "    return output_vec\n",
    "            \n",
    "top_debate['doc_vector'] = top_debate['speech_processed'].apply(lambda x: text_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.403232\n",
      "0.22371931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# See if model is acting logically\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "\n",
    "model = models.Word2Vec(\n",
    "        processed_text,\n",
    "        workers=4,     # Number of threads to run in parallel\n",
    "        min_count=10,  # Minimum word count threshold.\n",
    "        window=6,      # Number of words around target word to consider.\n",
    "        sg=0,          # Use CBOW because our corpus is small.\n",
    "        sample=1e-3 ,  # Penalize frequent words.\n",
    "        size=300,      # Word vector length.\n",
    "        hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "model.train(processed_text, total_examples=len(processed_text), epochs=10)\n",
    "          \n",
    "print(model.wv.similarity('environment', 'air'))\n",
    "print(model.wv.similarity('law', 'bill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out a bunch of combinations for the word2vec model builder. I didn't see a huge optimization through fiddling.\n",
    "the same parameter set really varied by each run\n",
    "\n",
    "|Description|Best Score|CV Var|\n",
    "|:---|:---:|:---:|\n",
    "|wordvec len 300|0.649|0.021|\n",
    "|wordvec len 200|0.642|0.043|\n",
    "|wordvec len 100|0.641|0.033|\n",
    "|min count 50|0.630|0.037|\n",
    "|min count 10|0.649|0.039|\n",
    "|min count 5 |0.633|0.022|\n",
    "|min count 7 |0.640|0.015|\n",
    "|window 6    |0.638|0.036|\n",
    "|window 12   |0.630|0.015|\n",
    "|window 30   |0.637|0.018|\n",
    "|window 15   |0.622|0.038|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# This frame used to test out different parameters in the word2vec model\n",
    "# Run this cell prior to rerunning pipelines below\n",
    "model = models.Word2Vec(\n",
    "        processed_text,\n",
    "        workers=4,     # Number of threads to run in parallel\n",
    "        min_count=10,  # Minimum word count threshold.\n",
    "        window=12,      # Number of words around target word to consider.\n",
    "        sg=0,          # Use CBOW because our corpus is small.\n",
    "        sample=1e-3 ,  # Penalize frequent words.\n",
    "        size=300,      # Word vector length.\n",
    "        hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "model.train(processed_text, total_examples=len(processed_text), epochs=10)\n",
    "\n",
    "def text_vector(doc):    \n",
    "    output_vec = np.zeros(model.vector_size)\n",
    "    for word in doc:\n",
    "        if word in model.wv.vocab:\n",
    "            output_vec += model[word]\n",
    "##### tried to use normalize but its doesn't like the input output_vec += normalize(model[word], axis=0)\n",
    "    return output_vec\n",
    "            \n",
    "top_debate['doc_vector'] = top_debate['speech_processed'].apply(lambda x: text_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.656\n",
      "Cross Val: 0.034\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy',\n",
       " 'clf__max_depth': 9,\n",
       " 'clf__n_estimators': 150,\n",
       " 'svd__n_components': 30}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = top_debate['party']\n",
    "X = pd.DataFrame(np.array(list(top_debate['doc_vector'])))\n",
    "pipeline = Pipeline([\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__criterion': ('entropy','gini'),\n",
    "    'clf__max_depth': (4,5,9,None),\n",
    "    'clf__n_estimators': (50,70,150),\n",
    "    'svd__n_components': (5,10,30,50, 70),    \n",
    "    #'tfidf__max_df': (0.5,0.8),\n",
    "    #'tfidf__min_df': (2,5,9,),   \n",
    "}\n",
    "\n",
    "grid_search_word2 = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search_word2.fit(X,y)\n",
    "\n",
    "print('Best score: %.3f'%grid_search_word2.best_score_)\n",
    "print('Cross Val: %.3f'%(np.std(cross_val_score(grid_search_word2.best_estimator_, X, y, cv=3))))\n",
    "print('Best parameters:')\n",
    "grid_search_word2.best_params_   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.654\n",
      "Cross Val: 0.012\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.2,\n",
       " 'clf__max_depth': 4,\n",
       " 'clf__n_estimators': 100,\n",
       " 'clf__subsample': 0.5,\n",
       " 'svd__n_components': 30}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Would liket to see Gradient Boost too\n",
    "y = top_debate['party']\n",
    "X = pd.DataFrame(np.array(list(top_debate['doc_vector'])))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__learning_rate': (0.2, 0.5,),\n",
    "    'clf__max_depth': (4,7,9, None,),           \n",
    "    'clf__n_estimators': (50, 70, 100,), \n",
    "    'clf__subsample': (0.3, 0.5, 0.7),\n",
    "    'svd__n_components': (30, 50,),       \n",
    "}\n",
    "grid_search_word2 = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search_word2.fit(X,y)\n",
    "\n",
    "print('Best score: %.3f'%grid_search_word2.best_score_)\n",
    "print('Cross Val: %.3f'%(np.std(cross_val_score(grid_search_word2.best_estimator_, X, y, cv=3))))\n",
    "print('Best parameters:')\n",
    "grid_search_word2.best_params_   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### ALL DEBATES\n",
    "### BOW Pipeline Using all Debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.579\n",
      "Best parameters: {'clf__criterion': 'entropy', 'clf__max_depth': 9, 'clf__n_estimators': 70, 'svd__n_components': 50, 'vect__max_df': 0.5, 'vect__max_features': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words using tfidf vectorizer\n",
    "# Training the BOW vectorizor\n",
    "# It looks like it wants to use very few features that appear in most of the documents - this seems like a good way to overfit\n",
    "bow_vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,      # if an integer vectorizer returns with most used words  \n",
    "    use_idf=False,          # Use IDF\n",
    "    norm=u'l2',             # Correction factor to treat long and short paragraphs equally\n",
    "    smooth_idf=True,        # Prevents divide-by-zero errors by adding one to all features\n",
    "    stop_words='english',  \n",
    "    lowercase=True,          \n",
    "                                 )\n",
    "pipeline = Pipeline([\n",
    "    ('vect', bow_vectorizer),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_features': (1000,),     # return top X used words\n",
    "    'vect__max_df': (0.5,),           # Drop words that appear in > x % of the paragraphs\n",
    "    'svd__n_components': (50,70,),   #50\n",
    "    'clf__max_depth': (4,7,9),           #9\n",
    "    'clf__n_estimators': (50, 70, 100,), #70\n",
    "    'clf__criterion': ('entropy',),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search.fit(dev_text['speech_clean'],dev_text['party'])\n",
    "\n",
    "print('Best score: %.3f'%grid_search.best_score_)\n",
    "print('Best parameters: \\n{}\\n'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BOW model has improved from some of my previous iterations and is leveraging a larger feature set. Using the max_df threshold is making it less of a traditional bag of most common words. Random Forest is prone to overfitting so lets see how much variance there is between the folds of the winning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54893617, 0.50643777, 0.6223176 ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When I look at the St. Dev of the winning model its clear this is model is overfit\n",
    "cross_val_score(grid_search.best_estimator_, dev_text['speech'],dev_text['party'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grandient Boost has a built in sampler to help with overfitting. Lets try this approach. To reduce fitting time I'm going to stick with 1000 features and 0.5 as the cutoff for super common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.579\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.2,\n",
       " 'clf__max_depth': 9,\n",
       " 'clf__n_estimators': 100,\n",
       " 'clf__subsample': 0.3,\n",
       " 'svd__n_components': 50,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 1000}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOW vectorizer with Gradient Boost\n",
    "bow_vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,      # if an integer vectorizer returns with most used words  \n",
    "    use_idf=False,          # Use IDF\n",
    "    norm=u'l2',             # Correction factor to treat long and short paragraphs equally\n",
    "    smooth_idf=True,        # Prevents divide-by-zero errors by adding one to all features\n",
    "    stop_words='english',  \n",
    "    lowercase=True,          \n",
    "                                 )\n",
    "pipeline = Pipeline([\n",
    "    ('vect', bow_vectorizer),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_features': (1000,),     \n",
    "    'vect__max_df': (0.5,),           # Drop words that appear in > x % of the paragraphs\n",
    "    'svd__n_components': (50,100),\n",
    "    'clf__max_depth': (4,7,9),\n",
    "    'clf__n_estimators': (10, 50, 100),\n",
    "    'clf__learning_rate': (0.8, 0.2),\n",
    "    'clf__subsample': (0.5, 0.3,)\n",
    "}\n",
    "\n",
    "grid_search_boost = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search_boost.fit(dev_text['speech_clean'],dev_text['party'])\n",
    "\n",
    "print('Best score: %.3f'%grid_search.best_score_)\n",
    "print('Best parameters:')\n",
    "grid_search_boost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5106383 , 0.527897  , 0.56652361])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When I look at the St. Dev of the winning model its clear this is model is overfit\n",
    "cross_val_score(grid_search_boost.best_estimator_, dev_text['speech'],dev_text['party'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boost Seems a tad less overfit the random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - repeat the same process to create a tfidf vectorizor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the model below I'm really uncomfortable taht it is giing sam number of components for svd as for number of estimators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.562\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'entropy',\n",
       " 'clf__max_depth': 4,\n",
       " 'clf__n_estimators': 100,\n",
       " 'svd__n_components': 50,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__min_df': 2}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF Optimizing th TFIDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,            # drop words that occur in more than half the paragraphs\n",
    "    min_df=2,              # Use words that appear >= 2x     \n",
    "    use_idf=True,          # Use IDF\n",
    "    norm=u'l2',            # Correction factor to treat long and short paragraphs equally\n",
    "    smooth_idf=True,        # Prevents divide-by-zero errors by adding one to all features\n",
    "    stop_words='english',  \n",
    "    lowercase=True,        \n",
    "    )\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False)),\n",
    "    ('clf', RandomForestClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.5,),\n",
    "    'tfidf__min_df': (2,),\n",
    "    'svd__n_components': (50,100, 150),\n",
    "    'clf__max_depth': (4,7,10, None),\n",
    "    'clf__n_estimators': (10,40,100),\n",
    "    'clf__criterion': ('entropy',),\n",
    "}\n",
    "\n",
    "grid_search_tfidf = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search_tfidf.fit(dev_text['speech_clean'],dev_text['party'])\n",
    "\n",
    "print( 'Best score: %.3f'%grid_search_tfidf.best_score_)\n",
    "print('Best parameters:')\n",
    "grid_search_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52765957, 0.53218884, 0.58369099])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance here also not great\n",
    "# Removing the Normalizer step made the accuracy much worse\n",
    "# Maybe I should give myself space to fiddle with TFIDF parameters with constant Tree and then p\n",
    "cross_val_score(grid_search_tfidf.best_estimator_, dev_text['speech'],dev_text['party'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.586\n",
      "Best parameters:/n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.2,\n",
       " 'clf__max_depth': 4,\n",
       " 'clf__n_estimators': 50,\n",
       " 'clf__subsample': 0.5,\n",
       " 'svd__n_components': 100,\n",
       " 'tfidf__max_df': 0.5,\n",
       " 'tfidf__min_df': 2,\n",
       " 'tfidf__norm': 'l2'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF \n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,            # drop words that occur in more than half the paragraphs\n",
    "    min_df=2,              # Use words that appear >= 2x     \n",
    "    use_idf=True,          # Use IDF\n",
    "    norm=u'l2',            # Correction factor to treat long and short paragraphs equally\n",
    "    smooth_idf=True,        # Prevents divide-by-zero errors by adding one to all features\n",
    "    stop_words='english',  \n",
    "    lowercase=True,        \n",
    "    )\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('norm', Normalizer(copy=False,)),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.5,),\n",
    "    'tfidf__min_df': (2,),\n",
    "    'tfidf__norm': ('l2',),\n",
    "    'svd__n_components': (70,100,200),\n",
    "    'clf__max_depth': (4,7,9),\n",
    "    'clf__n_estimators': (10, 50, 100),\n",
    "    'clf__learning_rate': (0.8, 0.2),\n",
    "    'clf__subsample': (0.5,)\n",
    "}\n",
    "\n",
    "grid_search_tfidf_boost = GridSearchCV(pipeline, parameters, refit=True)\n",
    "grid_search_tfidf_boost.fit(dev_text['speech_clean'],dev_text['party'])\n",
    "\n",
    "print( 'Best score: %.3f'%grid_search_tfidf_boost.best_score_)\n",
    "print('Best parameters:/n')\n",
    "grid_search_tfidf_boost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52765957, 0.527897  , 0.58369099])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When I look at the St. Dev of the winning model its clear this is model is overfit\n",
    "cross_val_score(grid_search_tfidf_boost.best_estimator_, dev_text['speech'],dev_text['party'] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
