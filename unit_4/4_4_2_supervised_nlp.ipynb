{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.2 [NLP: as a Supervised Problem](https://courses.thinkful.com/data-201v1/project/4.4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised NLP:\n",
    "    * Requires a pre-labelled dataset for training and testing \n",
    "    * generally interested in categorizing text in various ays\n",
    "\n",
    "Feature Generation - Bag of Words: for each sentence count how many times each words appears. We then use those counts as features (is this every word or just the relevant entitites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "leaves = gutenberg.raw('whitman-leaves.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)\n",
    "leaves = text_cleaner(leaves)\n",
    "\n",
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "leaves_doc = nlp(leaves)\n",
    "\n",
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "leaves_sents = [[sent, \"Whitman\"] for sent in leaves_doc.sents]\n",
    "leaves_sents = leaves_sents[:len(alice_sents)]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + leaves_sents)\n",
    "df_leaves_sents = pd.DataFrame(leaves_sents)\n",
    "\n",
    "# Load and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop\n",
    "                and not token.is_space]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        \n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            print(\"Calcuation Time %.3f\"%((time.time()-start_time)/60.0))\n",
    "            start_time = time.time()\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Calcuation Time 0.054\n",
      "Processing row 50\n",
      "Calcuation Time 1.069\n",
      "Processing row 100\n",
      "Calcuation Time 1.488\n",
      "Processing row 150\n",
      "Calcuation Time 1.068\n",
      "Processing row 200\n",
      "Calcuation Time 1.075\n",
      "Processing row 250\n",
      "Calcuation Time 1.022\n",
      "Processing row 300\n",
      "Calcuation Time 1.131\n",
      "Processing row 350\n",
      "Calcuation Time 0.986\n",
      "Processing row 400\n",
      "Calcuation Time 1.065\n",
      "Processing row 450\n",
      "Calcuation Time 0.644\n",
      "Processing row 500\n",
      "Calcuation Time 1.317\n",
      "Processing row 550\n",
      "Calcuation Time 0.986\n",
      "Processing row 600\n",
      "Calcuation Time 1.031\n",
      "Processing row 650\n",
      "Calcuation Time 1.136\n",
      "Processing row 700\n",
      "Calcuation Time 1.090\n",
      "Processing row 750\n",
      "Calcuation Time 1.138\n",
      "Processing row 800\n",
      "Calcuation Time 0.940\n",
      "Processing row 850\n",
      "Calcuation Time 0.927\n",
      "Processing row 900\n",
      "Calcuation Time 0.841\n",
      "Processing row 950\n",
      "Calcuation Time 0.919\n",
      "Processing row 1000\n",
      "Calcuation Time 1.282\n",
      "Processing row 1050\n",
      "Calcuation Time 0.846\n",
      "Processing row 1100\n",
      "Calcuation Time 1.583\n",
      "Processing row 1150\n",
      "Calcuation Time 1.148\n",
      "Processing row 1200\n",
      "Calcuation Time 1.114\n",
      "Processing row 1250\n",
      "Calcuation Time 0.812\n",
      "Processing row 1300\n",
      "Calcuation Time 0.941\n",
      "Processing row 1350\n",
      "Calcuation Time 0.839\n",
      "Processing row 1400\n",
      "Calcuation Time 1.080\n",
      "Processing row 1450\n",
      "Calcuation Time 1.028\n",
      "Processing row 1500\n",
      "Calcuation Time 0.913\n",
      "Processing row 1550\n",
      "Calcuation Time 0.936\n",
      "Processing row 1600\n",
      "Calcuation Time 1.005\n",
      "Processing row 1650\n",
      "Calcuation Time 0.838\n",
      "Processing row 0\n",
      "Calcuation Time 0.230\n",
      "Processing row 50\n",
      "Calcuation Time 4.546\n",
      "Processing row 100\n",
      "Calcuation Time 3.745\n",
      "Processing row 150\n",
      "Calcuation Time 3.315\n",
      "Processing row 200\n",
      "Calcuation Time 3.271\n",
      "Processing row 250\n",
      "Calcuation Time 3.628\n",
      "Processing row 300\n",
      "Calcuation Time 3.866\n",
      "Processing row 350\n",
      "Calcuation Time 4.460\n",
      "Processing row 400\n",
      "Calcuation Time 2.418\n",
      "Processing row 450\n",
      "Calcuation Time 2.955\n",
      "Processing row 500\n",
      "Calcuation Time 4.005\n",
      "Processing row 550\n",
      "Calcuation Time 3.833\n",
      "Processing row 600\n",
      "Calcuation Time 3.460\n",
      "Processing row 650\n",
      "Calcuation Time 2.631\n",
      "Processing row 700\n",
      "Calcuation Time 1.832\n",
      "Processing row 750\n",
      "Calcuation Time 2.543\n",
      "Processing row 800\n",
      "Calcuation Time 2.635\n",
      "Processing row 850\n",
      "Calcuation Time 2.200\n",
      "Processing row 900\n",
      "Calcuation Time 3.137\n",
      "Processing row 950\n",
      "Calcuation Time 3.389\n",
      "Processing row 1000\n",
      "Calcuation Time 2.982\n",
      "Processing row 1050\n",
      "Calcuation Time 3.002\n",
      "Processing row 1100\n",
      "Calcuation Time 2.138\n",
      "Processing row 1150\n",
      "Calcuation Time 2.738\n",
      "Processing row 1200\n",
      "Calcuation Time 4.541\n",
      "Processing row 1250\n",
      "Calcuation Time 4.288\n",
      "Processing row 1300\n",
      "Calcuation Time 2.325\n",
      "Processing row 1350\n",
      "Calcuation Time 2.788\n",
      "Processing row 1400\n",
      "Calcuation Time 2.745\n",
      "Processing row 1450\n",
      "Calcuation Time 2.806\n",
      "Processing row 1500\n",
      "Calcuation Time 2.749\n",
      "Processing row 1550\n",
      "Calcuation Time 3.060\n",
      "Processing row 1600\n",
      "Calcuation Time 2.872\n",
      "Processing row 1650\n",
      "Calcuation Time 2.016\n",
      "Processing row 1700\n",
      "Calcuation Time 3.207\n",
      "Processing row 1750\n",
      "Calcuation Time 2.557\n",
      "Processing row 1800\n",
      "Calcuation Time 2.341\n",
      "Processing row 1850\n",
      "Calcuation Time 2.482\n",
      "Processing row 1900\n",
      "Calcuation Time 3.390\n",
      "Processing row 1950\n",
      "Calcuation Time 3.458\n",
      "Processing row 2000\n",
      "Calcuation Time 2.726\n",
      "Processing row 2050\n",
      "Calcuation Time 3.325\n",
      "Processing row 2100\n",
      "Calcuation Time 46.572\n",
      "Processing row 2150\n",
      "Calcuation Time 487.367\n",
      "Processing row 2200\n",
      "Calcuation Time 2.621\n",
      "Processing row 2250\n",
      "Calcuation Time 1.297\n",
      "Processing row 2300\n",
      "Calcuation Time 2.057\n",
      "Processing row 2350\n",
      "Calcuation Time 2.342\n",
      "Processing row 2400\n",
      "Calcuation Time 2.357\n",
      "Processing row 2450\n",
      "Calcuation Time 2.952\n",
      "Processing row 2500\n",
      "Calcuation Time 2.415\n",
      "Processing row 2550\n",
      "Calcuation Time 2.299\n",
      "Processing row 2600\n",
      "Calcuation Time 2.082\n",
      "Processing row 2650\n",
      "Calcuation Time 1.813\n",
      "Processing row 2700\n",
      "Calcuation Time 2.128\n",
      "Processing row 2750\n",
      "Calcuation Time 1.874\n",
      "Processing row 2800\n",
      "Calcuation Time 2.271\n",
      "Processing row 2850\n",
      "Calcuation Time 2.265\n",
      "Processing row 2900\n",
      "Calcuation Time 1.837\n",
      "Processing row 2950\n",
      "Calcuation Time 3.218\n",
      "Processing row 3000\n",
      "Calcuation Time 2.808\n",
      "Processing row 3050\n",
      "Calcuation Time 2.331\n",
      "Processing row 3100\n",
      "Calcuation Time 2.829\n",
      "Processing row 3150\n",
      "Calcuation Time 3.109\n",
      "Processing row 3200\n",
      "Calcuation Time 1.680\n",
      "Processing row 3250\n",
      "Calcuation Time 2.631\n",
      "Processing row 3300\n",
      "Calcuation Time 3.471\n",
      "Processing row 3350\n",
      "Calcuation Time 1.768\n",
      "Processing row 3400\n",
      "Calcuation Time 2.344\n",
      "Processing row 3450\n",
      "Calcuation Time 1.860\n",
      "Processing row 3500\n",
      "Calcuation Time 2.176\n",
      "Processing row 3550\n",
      "Calcuation Time 2.424\n",
      "Processing row 3600\n",
      "Calcuation Time 2.125\n",
      "Processing row 0\n",
      "Calcuation Time 0.021\n",
      "Processing row 50\n",
      "Calcuation Time 1.060\n",
      "Processing row 100\n",
      "Calcuation Time 1.032\n",
      "Processing row 150\n",
      "Calcuation Time 1.051\n",
      "Processing row 200\n",
      "Calcuation Time 0.817\n",
      "Processing row 250\n",
      "Calcuation Time 0.713\n",
      "Processing row 300\n",
      "Calcuation Time 0.793\n",
      "Processing row 350\n",
      "Calcuation Time 1.319\n",
      "Processing row 400\n",
      "Calcuation Time 1.274\n",
      "Processing row 450\n",
      "Calcuation Time 1.748\n",
      "Processing row 500\n",
      "Calcuation Time 0.862\n",
      "Processing row 550\n",
      "Calcuation Time 0.689\n",
      "Processing row 600\n",
      "Calcuation Time 0.568\n",
      "Processing row 650\n",
      "Calcuation Time 1.074\n",
      "Processing row 700\n",
      "Calcuation Time 1.923\n",
      "Processing row 750\n",
      "Calcuation Time 1.079\n",
      "Processing row 800\n",
      "Calcuation Time 0.823\n",
      "Processing row 850\n",
      "Calcuation Time 1.140\n",
      "Processing row 900\n",
      "Calcuation Time 0.907\n",
      "Processing row 950\n",
      "Calcuation Time 1.113\n",
      "Processing row 1000\n",
      "Calcuation Time 0.889\n",
      "Processing row 1050\n",
      "Calcuation Time 1.801\n",
      "Processing row 1100\n",
      "Calcuation Time 1.468\n",
      "Processing row 1150\n",
      "Calcuation Time 1.558\n",
      "Processing row 1200\n",
      "Calcuation Time 0.750\n",
      "Processing row 1250\n",
      "Calcuation Time 1.413\n",
      "Processing row 1300\n",
      "Calcuation Time 1.606\n",
      "Processing row 1350\n",
      "Calcuation Time 1.400\n",
      "Processing row 1400\n",
      "Calcuation Time 0.907\n",
      "Processing row 1450\n",
      "Calcuation Time 0.536\n",
      "Processing row 1500\n",
      "Calcuation Time 1.021\n",
      "Processing row 1550\n",
      "Calcuation Time 0.410\n",
      "Processing row 1600\n",
      "Calcuation Time 0.472\n",
      "Processing row 1650\n",
      "Calcuation Time 0.823\n"
     ]
    }
   ],
   "source": [
    "# Parse the sentences from the 3 datasets\n",
    "# This takes forever\n",
    "alice_wordcounts = bow_features(pd.DataFrame(alice_sents), common_words)\n",
    "persuasion_wordcounts = bow_features(pd.DataFrame(persuasion_sents), common_words)\n",
    "leaves_wordcounts = bow_features(pd.DataFrame(leaves_sents), common_words)\n",
    "\n",
    "# Create 1 dataframe with all 3 datasources, \n",
    "# keep index so the sentence number can be used \n",
    "# if dataset pulled from pickle file (which was not accepting spacy objects)\n",
    "all_wordcounts = alice_wordcounts.append(\n",
    "    persuasion_wordcounts,ignore_index= False).append(\n",
    "    leaves_wordcounts, ignore_index=False)\n",
    "\n",
    "# Creating index that does not repeat itself, original index can still \n",
    "# be accessed for matching purposes\n",
    "all_wordcounts = all_wordcounts.reset_index()\n",
    "\n",
    "# Create function for pickling a file\n",
    "import pickle\n",
    "def pickle_file(data, file_name):\n",
    "    file = open(file_name, 'wb')\n",
    "    pickle.dump(data,file, protocol=-1)\n",
    "    file.close()\n",
    "\n",
    "# Pickle word count, must drop the scpacy objecte\n",
    "pickle_file(all_wordcounts.drop(['text_sentence'], 1), 'nlp_wordcounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wordcounts = alice_wordcounts.append(\n",
    "    persuasion_wordcounts.iloc[:len(alice_sents),:],ignore_index= True).append(\n",
    "    leaves_wordcounts, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_source\n",
       "Austen     1669\n",
       "Carroll    1669\n",
       "Whitman    1669\n",
       "Name: text_sentence, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wordcounts.groupby('text_source').count()['text_sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Challenge 0:\n",
    "\n",
    "Logistic regression best performance: 93% \n",
    "\n",
    "Exploration Areas:\n",
    "* Other modeling techniques (SVM?), \n",
    "* More spaCy features - grammar, phrases, POS, etc.,  \n",
    "* Sentence level features - (number of words, amount of punctuation)\n",
    "* Including contextual info - words repeated from one sentence to the next, etc\n",
    "\n",
    "Make sure to design your models on the test set, or use cross_validation with multiple folds, and see if you can get accuracy above 90%.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating the training set\n",
    "carroll_austen = all_wordcounts[(\n",
    "    all_wordcounts['text_source']=='Carroll')|(\n",
    "    all_wordcounts['text_source']=='Austen')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(carroll_austen.drop(['text_sentence','text_source'], 1))\n",
    "Y = carroll_austen['text_source']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.510\n",
      "\n",
      "Test set score: 0.484\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='rbf', C = 0.1)\n",
    "train = svc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% svc.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.687\n",
      "\n",
      "Test set score: 0.693\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='rbf', C = 2)\n",
    "train = svc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% svc.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.866\n",
      "\n",
      "Test set score: 0.850\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='rbf', C = 30)\n",
    "train = svc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% svc.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.900\n",
      "\n",
      "Test set score: 0.883\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='rbf', C = 100)\n",
    "train = svc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% svc.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier is overfitting as we increase C (which is to be expected). I don't have huge confidence in this performing well on Walt Whitman but lets see how frequently the model is able to correctly identify Louis Carroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Challenge 1:\n",
    "Find out whether your new model is good at identifying \n",
    "* Alice in Wonderland vs any other work, \n",
    "* Persuasion vs any other work, or \n",
    "* Austen vs any other work.  \n",
    "\n",
    "This will involve pulling a new book from the Project Gutenberg corpus (print(gutenberg.fileids()) for a list) and processing it.\n",
    "\n",
    "Record your work for each challenge in a notebook and submit it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data set with just Carroll and Walt Whitman\n",
    "carroll_whitman = all_wordcounts[(\n",
    "    all_wordcounts['text_source']=='Carroll')|(\n",
    "    all_wordcounts['text_source']=='Whitman')].drop(\n",
    "    'index',1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitman = all_wordcounts[all_wordcounts['text_source']=='Whitman'].drop(\n",
    "    'index',1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_test_whitman = np.concatenate((X_train[y_train[y_train=='Carroll'].index],\n",
    "    whitman.drop(['text_sentence','text_source'], 1)), axis=0)\n",
    "y_test_whitman = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Whitman'] * whitman.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Leaves: 0.131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>661</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitman</th>\n",
       "      <td>1277</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Carroll     661      352\n",
       "Whitman    1277      392"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='rbf', C = 100)\n",
    "train = svc.fit(X, Y)\n",
    "\n",
    "print('Score Leaves: %.3f'% svc.score(X_test_whitman, y_test_whitman))\n",
    "# Model.\n",
    "\n",
    "svc_whitman_predicted = svc.predict(X_test_whitman)\n",
    "pd.crosstab(y_test_whitman, svc_whitman_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Leaves: 0.089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>774</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitman</th>\n",
       "      <td>1569</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Carroll     774      239\n",
       "Whitman    1569      100"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='rbf', C = 100)\n",
    "train = svc.fit(X_train, y_train)\n",
    "\n",
    "print('Score Leaves: %.3f'% svc.score(X_test_whitman, y_test_whitman))\n",
    "# Model.\n",
    "\n",
    "svc_whitman_predicted = svc.predict(X_test_whitman)\n",
    "pd.crosstab(y_test_whitman, svc_whitman_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model failed to accurately predict Carroll well smh. \n",
    "I'm going to try this where I use all of the Carroll/Austen text to train the model and then all of the Carroll/Whitman to text the model's ability to accurately classify.\n",
    "I don't see this going well since the classification is using information from Austen and Carroll to make predictions rather than Carroll/NOT Carroll. Setting up the model as Carroll NOT Carroll may have had more success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Leaves: 0.176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>163</td>\n",
       "      <td>1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitman</th>\n",
       "      <td>1277</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        Austen  Carroll\n",
       "text_source                 \n",
       "Carroll         163     1506\n",
       "Whitman        1277      392"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "svc = SVC(gamma='auto', kernel='rbf', C = 100)\n",
    "train = svc.fit(X, Y)\n",
    "\n",
    "Y_whitman = carroll_whitman['text_source']\n",
    "X_whitman = carroll_whitman.drop(['text_sentence','text_source'], 1)\n",
    "print('Score Leaves: %.3f'% svc.score(X_test_whitman, y_test_whitman))\n",
    "\n",
    "# To get a random set of sentences I'm creating a training and tear set\n",
    "# Could also just sort my data\n",
    "svc_whitman_predicted = svc.predict(X_whitman)\n",
    "pd.crosstab(Y_whitman, svc_whitman_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct: 0.834\n"
     ]
    }
   ],
   "source": [
    "print('Percent Correct: %.3f'% ((1277+1506)/len(Y_whitman)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I do the calculatin myself of Carroll not Carroll its actually not that awful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next\t0\tnext\tFalse\tFalse\tXxxx\tADJ\tJJ\n",
      "week\t5\tweek\tFalse\tFalse\txxxx\tNOUN\tNN\n",
      "I\t10\t-PRON-\tFalse\tFalse\tX\tPRON\tPRP\n",
      "'ll\t11\twill\tFalse\tFalse\t'xx\tVERB\tMD\n",
      "  \t15\t  \tFalse\tTrue\t  \tSPACE\t_SP\n",
      "be\t17\tbe\tFalse\tFalse\txx\tVERB\tVB\n",
      "in\t20\tin\tFalse\tFalse\txx\tADP\tIN\n",
      "Madrid\t23\tmadrid\tFalse\tFalse\tXxxxx\tPROPN\tNNP\n",
      ".\t29\t.\tTrue\tFalse\t.\tPUNCT\t.\n"
     ]
    }
   ],
   "source": [
    "# what we can extract from tokens\n",
    "doc = nlp(\"Next week I'll   be in Madrid.\")\n",
    "for token in doc:\n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
    "        token.text,\n",
    "        token.idx,       # index of where the token starts\n",
    "        token.lemma_,    # the base word\n",
    "        token.is_punct,  # bool of if the token is punctuation\n",
    "        token.is_space,  # bool of if the token is a space\n",
    "        token.shape_,    # capital/lower case X's in length of the token\n",
    "        token.pos_,      # the part of speach of the token\n",
    "        token.tag_       # seem to be abreiations for the pos\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are apples.\n",
      "These are oranges.\n",
      "These are apples.\n",
      "These are oranges.\n"
     ]
    }
   ],
   "source": [
    "# sentence tagging\n",
    "doc = nlp(\"These are apples. These are oranges.\")\n",
    "[print('{}'.format(sent)) for sent in doc.sents]\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\n",
      "PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in sentences.iloc[0,0].ents:\n",
    "    #print(len(token.shape_))\n",
    "    print(ent.text)\n",
    "    print(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pos = [token.pos_ for token in sentences.iloc[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'PROPN': 2,\n",
       "         'VERB': 13,\n",
       "         'PART': 2,\n",
       "         'ADV': 3,\n",
       "         'ADJ': 3,\n",
       "         'ADP': 8,\n",
       "         'NOUN': 12,\n",
       "         'DET': 5,\n",
       "         'PUNCT': 10,\n",
       "         'CCONJ': 6,\n",
       "         'PRON': 3})"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'say', 'alice', 'be', 'not', 'think', 'go', 'little', 'the', 'know']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item[0] for item in Counter(allwords).most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_nouns(text):\n",
    "    noun_chunks = [str(noun_chunk)\n",
    "                   for noun_chunk \n",
    "                   in text.noun_chunks]\n",
    "    return [item[0] for item in Counter(noun_chunks).most_common(20)]\n",
    "\n",
    "alice_nouns = bag_of_nouns(alice_doc)\n",
    "persuasion_nouns = bag_of_nouns(persuasion_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN\n",
      "VERB\n",
      "VERB\n",
      "PART\n",
      "VERB\n",
      "ADV\n",
      "ADJ\n"
     ]
    }
   ],
   "source": [
    "for token in sentences.iloc[0,0][:7]:\n",
    "    #print(len(token.shape_))\n",
    "    print(token.pos_)\n",
    "    #print(ent.label_)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34363"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alice_doc = Doc\n",
    "# t = token \n",
    "\n",
    "# for every token in the doc print the token\n",
    "[t for t in alice_doc]\n",
    "\n",
    "# for every token in the doc print the token as a string\n",
    "[t.text for t in alice_doc[:15]]\n",
    "\n",
    "# length of the doc (in tokens)\n",
    "len(alice_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[to]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(alice_doc[3].subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Bag some words\n",
    "* exclude stopwords & punctuation\n",
    "* stick to the most common 2000 lemmas for each text\n",
    "\n",
    "# Random Forest on BOW\n",
    "* overfitting is a known problem when using bag of words since it basically involves throwing a massive number of features at a model\n",
    "* some features will capture noise in the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.987460815047022\n",
      "\n",
      "Test set score: 0.8895676691729323\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% rfc.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9862068965517241\n",
      "\n",
      "Test set score: 0.8905075187969925\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% rfc.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mary', 'town', 'leave', 'continue', 'aware', 'pardon', 'nearer',\n",
       "       'curiosity', 'are', 'thought',\n",
       "       ...\n",
       "       'day', 'doubt', 'picture', 'beat', 'sharp', 'growl', 'hall', 'game',\n",
       "       'vanish', 'fan'],\n",
       "      dtype='object', length=774)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.drop(['text_sentence','text_source'], 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.078957</td>\n",
       "      <td>alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.056796</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.053473</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.037857</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.027391</td>\n",
       "      <td>-PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.017797</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.015814</td>\n",
       "      <td>anne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.014607</td>\n",
       "      <td>turtle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.013414</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.013019</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.012220</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.012095</td>\n",
       "      <td>captain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.009213</td>\n",
       "      <td>dormouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.008899</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.008474</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0.008049</td>\n",
       "      <td>rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.007541</td>\n",
       "      <td>duchess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.007495</td>\n",
       "      <td>elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.007375</td>\n",
       "      <td>gryphon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.006638</td>\n",
       "      <td>hatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.006625</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.006276</td>\n",
       "      <td>why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.006128</td>\n",
       "      <td>remark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.005783</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.005712</td>\n",
       "      <td>hare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.005636</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.005631</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.005496</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005432</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.005156</td>\n",
       "      <td>oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>nervous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>necessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>musgroves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>regret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>avoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>danger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>dreadfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>excite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>shriek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>angrily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>engage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>finger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>sleepy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>shrill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>favour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>fan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     importances    features\n",
       "474     0.078957       alice\n",
       "566     0.056796          be\n",
       "282     0.053473         say\n",
       "565     0.037857         not\n",
       "753     0.027391      -PRON-\n",
       "506     0.017797        will\n",
       "373     0.015814        anne\n",
       "550     0.014607      turtle\n",
       "676     0.013414       queen\n",
       "526     0.013019         mrs\n",
       "463     0.012220        king\n",
       "665     0.012095     captain\n",
       "697     0.009213    dormouse\n",
       "245     0.008899         cat\n",
       "712     0.008474       mouse\n",
       "652     0.008049      rabbit\n",
       "527     0.007541     duchess\n",
       "695     0.007495      elliot\n",
       "242     0.007375     gryphon\n",
       "298     0.006638      hatter\n",
       "529     0.006625          mr\n",
       "524     0.006276         why\n",
       "401     0.006128      remark\n",
       "590     0.005783     charles\n",
       "230     0.005712        hare\n",
       "139     0.005636        what\n",
       "111     0.005631        know\n",
       "729     0.005496         and\n",
       "24      0.005432        head\n",
       "517     0.005156          oh\n",
       "..           ...         ...\n",
       "672     0.000000         inn\n",
       "456     0.000000       after\n",
       "564     0.000000     nervous\n",
       "656     0.000000   necessary\n",
       "647     0.000000   musgroves\n",
       "108     0.000000         ago\n",
       "636     0.000000      regret\n",
       "77      0.000000       avoid\n",
       "614     0.000000      chance\n",
       "128     0.000000      danger\n",
       "609     0.000000       style\n",
       "152     0.000000  dreadfully\n",
       "572     0.000000      excite\n",
       "361     0.000000      guinea\n",
       "182     0.000000      highly\n",
       "558     0.000000      shriek\n",
       "467     0.000000         kid\n",
       "552     0.000000     angrily\n",
       "549     0.000000        rule\n",
       "545     0.000000      simple\n",
       "207     0.000000      engage\n",
       "210     0.000000        inch\n",
       "214     0.000000        fish\n",
       "222     0.000000      finger\n",
       "666     0.000000       power\n",
       "498     0.000000      sleepy\n",
       "250     0.000000      shrill\n",
       "484     0.000000      favour\n",
       "261     0.000000         son\n",
       "773     0.000000         fan\n",
       "\n",
       "[774 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance = pd.DataFrame(data = {'importances':rfc.feature_importances_, 'features':word_counts.drop(['text_sentence','text_source'], 1).columns})\n",
    "df_importance.sort_values(by='importances', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## BoW with Logistic Regression\n",
    "\n",
    "Let's try a technique with some protection against overfitting due to extraneous features  logistic regression with ridge regularization (from ridge regression, also called L2 regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 1561) (3190,)\n",
      "Training set score: 0.952\n",
      "\n",
      "Test set score: 0.918\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score: %.3f'%lr.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'%lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 1561) (3190,)\n",
      "Training set score: 0.897\n",
      "\n",
      "Test set score: 0.883\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', C=.1)\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score: %.3f'% lr.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 1561) (3190,)\n",
      "Training set score: 0.979\n",
      "\n",
      "Test set score: 0.906\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', C=10)\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score: %.3f'% lr.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 1561) (3190,)\n",
      "Training set score: 0.985\n",
      "\n",
      "Test set score: 0.895\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', C=100)\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "print('Training set score: %.3f'% lr.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Logistic regression performs a bit better than the random forest.  \n",
    "\n",
    "# BoW with Gradient Boosting\n",
    "\n",
    "And finally, let's see what gradient boosting can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.886\n",
      "\n",
      "Test set score: 0.874\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% clf.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8830721003134796\n",
      "\n",
      "Test set score: 0.8698308270676691\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: %.3f'% clf.score(X_train, y_train))\n",
    "print('\\nTest set score: %.3f'% clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Looks like logistic regression is the winner, but there's room for improvement.\n",
    "\n",
    "# Same model, new inputs\n",
    "\n",
    "What if we feed the model a different novel by Jane Austen, like _Emma_?  Will it be able to distinguish Austen from Carroll with the same level of accuracy if we insert a different sample of Austen's writing?\n",
    "\n",
    "First, we need to process _Emma_ the same way we processed the other data, and combine it with the Alice data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to\n"
     ]
    }
   ],
   "source": [
    "# Clean the Emma data.\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma)\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse our cleaned data.\n",
    "emma_doc = nlp(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into sentences.\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]\n",
    "\n",
    "# Emma is quite long, let's cut it down to the same length as Alice.\n",
    "emma_sents = emma_sents[0:len(alice_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Calcuation Time 0.003\n",
      "Processing row 50\n",
      "Calcuation Time 0.072\n",
      "Processing row 100\n",
      "Calcuation Time 0.046\n",
      "Processing row 150\n",
      "Calcuation Time 0.058\n",
      "Processing row 200\n",
      "Calcuation Time 0.073\n",
      "Processing row 250\n",
      "Calcuation Time 0.094\n",
      "Processing row 300\n",
      "Calcuation Time 0.072\n",
      "Processing row 350\n",
      "Calcuation Time 0.061\n",
      "Processing row 400\n",
      "Calcuation Time 0.056\n",
      "Processing row 450\n",
      "Calcuation Time 0.041\n",
      "Processing row 500\n",
      "Calcuation Time 0.054\n",
      "Processing row 550\n",
      "Calcuation Time 0.043\n",
      "Processing row 600\n",
      "Calcuation Time 0.048\n",
      "Processing row 650\n",
      "Calcuation Time 0.047\n",
      "Processing row 700\n",
      "Calcuation Time 0.050\n",
      "Processing row 750\n",
      "Calcuation Time 0.042\n",
      "Processing row 800\n",
      "Calcuation Time 0.045\n",
      "Processing row 850\n",
      "Calcuation Time 0.043\n",
      "Processing row 900\n",
      "Calcuation Time 0.046\n",
      "Processing row 950\n",
      "Calcuation Time 0.050\n",
      "Processing row 1000\n",
      "Calcuation Time 0.044\n",
      "Processing row 1050\n",
      "Calcuation Time 0.045\n",
      "Processing row 1100\n",
      "Calcuation Time 0.056\n",
      "Processing row 1150\n",
      "Calcuation Time 0.073\n",
      "Processing row 1200\n",
      "Calcuation Time 0.036\n",
      "Processing row 1250\n",
      "Calcuation Time 0.027\n",
      "Processing row 1300\n",
      "Calcuation Time 0.039\n",
      "Processing row 1350\n",
      "Calcuation Time 0.036\n",
      "Processing row 1400\n",
      "Calcuation Time 0.032\n",
      "Processing row 1450\n",
      "Calcuation Time 0.041\n",
      "Processing row 1500\n",
      "Calcuation Time 0.045\n",
      "Processing row 1550\n",
      "Calcuation Time 0.056\n",
      "Processing row 1600\n",
      "Calcuation Time 0.059\n",
      "Processing row 1650\n",
      "Calcuation Time 0.056\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Build a new Bag of Words data frame for Emma word counts.\n",
    "# We'll use the same common words from Alice and Persuasion.\n",
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "emma_bow = bow_features(emma_sentences, common_words)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.703466666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1158</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>535</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1158       21\n",
       "Carroll     535      161"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can model it!\n",
    "# Let's use logistic regression again.\n",
    "\n",
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_Emma_test = np.concatenate((\n",
    "    X_train[y_train[y_train=='Carroll'].index],\n",
    "    emma_bow.drop(['text_sentence','text_source'], 1)\n",
    "), axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
    "\n",
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.6498881431767338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1413</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>683</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1413      256\n",
       "Carroll     683      330"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can model it!\n",
    "# Let's use logistic regression again.\n",
    "\n",
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_Emma_test = np.concatenate((\n",
    "    X_train[y_train[y_train=='Carroll'].index],\n",
    "    emma_bow.drop(['text_sentence','text_source'], 1)\n",
    "), axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
    "\n",
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
